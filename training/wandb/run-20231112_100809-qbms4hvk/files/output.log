
Epoch[1] Iteration[1/268], loss: 6.4066, nitc_loss: 4.5779, ss_loss: 2.0207, citc_loss: 0.0004, ritc_loss: -0.1924, Base Lr: 1.00e-06
Epoch 1 done. Time per batch: 5.732[s] Speed: 20.9[samples/s]
Traceback (most recent call last):
  File "/home/jovyan/workspace/BA-PRE_THESIS/REPORT/training/TBPR-CLIP_vietnamese_training.py", line 191, in <module>
    eval_result = test(
  File "/opt/conda/envs/tbps-clip/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/jovyan/workspace/BA-PRE_THESIS/paper_clones/TBPS-CLIP/misc/eval.py", line 21, in test
    text_feat = F.normalize(model.encode_text(text), dim=-1)
  File "/home/jovyan/workspace/BA-PRE_THESIS/REPORT/training/TBPR-CLIP_vietnamese_training.py", line 104, in encode_text
    return self.text_encoder.encode(texts, convert_to_tensor=True, device=self.device)
  File "/opt/conda/envs/tbps-clip/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py", line 156, in encode
    length_sorted_idx = np.argsort([-self._text_length(sen) for sen in sentences])
  File "/opt/conda/envs/tbps-clip/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py", line 156, in <listcomp>
    length_sorted_idx = np.argsort([-self._text_length(sen) for sen in sentences])
  File "/opt/conda/envs/tbps-clip/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py", line 571, in _text_length
    return sum([len(t) for t in text])      #Sum of length of individual strings
  File "/opt/conda/envs/tbps-clip/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py", line 571, in <listcomp>
    return sum([len(t) for t in text])      #Sum of length of individual strings
  File "/opt/conda/envs/tbps-clip/lib/python3.9/site-packages/torch/_tensor.py", line 893, in __len__
    raise TypeError("len() of a 0-d tensor")
TypeError: len() of a 0-d tensor